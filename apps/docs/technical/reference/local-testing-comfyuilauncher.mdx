---
title: "Develop in ComfyUI-Launcher"
description: "ComfyUI-Launcher Development Guide"
icon: "code"
---
[ComfyUI-Launcher](https://github.com/ComfyWorkflows/ComfyUI-Launcher) allows you to easily launch multiple ComfyUI workspaces. Following [RunPod.md](https://github.com/ComfyWorkflows/ComfyUI-Launcher/blob/main/cloud/RUNPOD.md), we can deploy ComfyUI-Launcher to RunPod.

You can monitor the container logs through Runpod, which is very helpful for debugging issues as you install nodes. In my experience, hacking on ComfyUI workflows require a decent amount of debugging around installing nodes.

I also recommend setting up SSH public keys, so you can directly ssh into the GPU server. This will help us with installing custom nodes, and setting up ssh tunnels.

ComfyUI-Launcher will create two folders:
- `/workspace/comfyui_launcher_models` - where all the models will be stored
- `/workspace/comfyui_launcher_projects` - where all the ComfyUI workspaces will be stored

You can create multiple ComfyUI workspaces, and they will live in `/workspace/comfyui_launcher_projects/{workspace}/comfyui` 
<Note>
Ignore the `/workspace/comfyui_launcher_projects/{workspace}/comfyui/models` directory - all of your models will be in `/workspace/comfyui_launcher_models`
</Note>
When you create an “empty” workflow, you will see the new workspace with the same name. Note, you have to install a model in the ComfyUI manager GUI so the “Load Checkpoint” node can find a model.

Enjoy generating your first purple bottle image.

## Step 1: Install ComfyStream

Follow [ComfyWorkflows/ComfyUI-Launcher?tab=readme-ov-file#quick-start](https://github.com/ComfyWorkflows/ComfyUI-Launcher?tab=readme-ov-file#quick-start) for creating a ComfyUI-Launcher container


First, we install Conda
```bash
cd /workspace
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
./Miniconda3-latest-Linux-x86_64.sh
export CONDA_PATH=$HOME/miniconda3
eval "$($CONDA_PATH/bin/conda shell.bash hook)"
```
Verify Conda has been installed using `which conda` - you should see “/root/miniconda3/bin/conda”

```bash
export CONDA_PATH=$HOME/miniconda3
eval "$($CONDA_PATH/bin/conda shell.bash hook)"
```

Next, we create and activate a Conda environment
```bash
conda create -n comfystream python=3.11
conda activate comfystream
conda install pytorch torchvision -c pytorch
pip install twilio aiortc torchaudio scikit-image && pip install . 
```

Next, we install ComfyStream
```bash
cd /workspace
git clone https://github.com/yondonfu/comfystream.git
cd comfystream
pip install .
```

After that, we copy the `tensor_utils` nodes into the `custom_nodes` folder in the ComfyUI workspace

```bash
cp -r nodes/tensor_utils /workspace/comfyui_launcher_projects/{workspace}/comfyui/custom_nodes
```

## Step 2: Install DepthAnything Tensorrt Node

The `https://github.com/yuvraj108c/ComfyUI-Depth-Anything-Tensorrt` custom node generates depth maps from images. Installing the node is pretty manual. 

**Installation**
```bash
cd /workspace/comfyui_launcher_projects/{workspace}/comfyui/custom_nodes
git clone https://github.com/yuvraj108c/ComfyUI-Depth-Anything-Tensorrt.git
cd ./ComfyUI-Depth-Anything-Tensorrt
pip install -r requirements.txt
```

**Download and Build Tensorrt Engine**
```bash
wget -O depth_anything_vitl14.onnx https://huggingface.co/yuvraj108c/Depth-Anything-2-Onnx/resolve/main/depth_anything_v2_vitb.onnx?download=true
python export_trt.py
mkdir -p /workspace/comfyui_launcher_models/tensorrt/depth-anything/
mv depth_anything_vitl14-fp16.engine /workspace/comfyui_launcher_models/tensorrt/depth-anything/
```

**Test Out in Depth Map Generation in ComfyUI**

- Open up the custom node manager, and you should see **`ComfyUI Depth Anything TensorRT`** as a custom node that's installed.
- You have to click on “Restart”, and reload the browser.
- If you double-click on an empty part of the canvas, you should be able to search and find `Depth Anything Tensorrt`.  Add it to the canvas.
    - If this doesn't show up, try and see if it's because the custom node is installed correctly.  If not, you can try to “fix it”.  The fixing process will take a while, since it'll be installing some packages.
- Add a ”Load Image” node as the input, and the “Preview Image” node as the output.  You should be able to pick an image and see the depth map.

# Step 3: Bring Up ComfyStream Server

Tunnel to open up UDP connection

- On the remote server (remote_host), run: `socat TCP4-LISTEN:4321,fork UDP4:127.0.0.1:5678`
- On the local machine: Open an SSH tunnel, run `ssh -L 4321:localhost:4321 {remote_user@remote_host and other params from Runpod ssh cmd}`
- On the local machine, run `socat UDP4-LISTEN:1234,fork TCP4:127.0.0.1:4321`

Traffic sent to `localhost:1234` on the local machine will be forwarded over the SSH tunnel and will reach `127.0.0.1:5678` on the remote server.
er

```bash
cd /workspace/comfystream
pip install -r requirements.txt
python install.py --workspace /workspace/comfyui_launcher_projects/{workspace}/comfyui
```

Open another terminal, ssh into the Runpod terminal:
    - You should find "SSH over exposed TCP" value in Runpod.
    - Copy that command, and add `-L 8888:localhost:8888`
    <Note>For example: `ssh -L 8888:localhost:8888 root@{runpod_ip} -p 16974 -i ~/.ssh/id_ed25519`</Note>

Run ComfyStream:
```bash
python server/app.py --workspace /workspace/comfyui_launcher_projects/{workspace}/comfyui --media-ports=5678
```

We should now have the ComfyStream server running on port `8888`, with media port `5678` listening on UDP.  It's also using the same workspace and sharing the available nodes / models as the ComfyUI engine you were using.

Traffic sent to `localhost:1234` on the local machine will be forwarded over the SSH tunnel and will reach `127.0.0.1:5678` on the remote server.

# Step 4: Run the Front End

Follow the guide [Run ComfyStream UI](./local-testing-comfystream-ui) to start a live stream with new development environment
